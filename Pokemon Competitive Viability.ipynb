{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "Notebook is an expansion of work done by Nicholas Veduvali on Kaggle and as a result most of the code is his or based on his. He achieved a test set RMSE of 1.21 with his best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Basics and Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:02.923621Z",
     "start_time": "2019-08-20T22:46:01.472393Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:03.455659Z",
     "start_time": "2019-08-20T22:46:02.925578Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.utils import resample \n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:05.480276Z",
     "start_time": "2019-08-20T22:46:03.457655Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\steph\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\steph\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\steph\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\steph\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\steph\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\steph\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:05.486262Z",
     "start_time": "2019-08-20T22:46:05.482271Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:05.513212Z",
     "start_time": "2019-08-20T22:46:05.488848Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pokemon-data: all the pokemon in the game up to gen 7 and relavent data about them incuding stats, moves, and abilities\n",
    "- move-data: all moves in the game and their info such as power type and accuracy\n",
    "- typetable: type effectiveness chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:05.554103Z",
     "start_time": "2019-08-20T22:46:05.515208Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data/pokemon-data.csv', delimiter=';')\n",
    "mdf = pd.read_csv('Data/move-data.csv')\n",
    "tdf = pd.read_csv('Data/typetable.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Most preprocessing was done based on work from Nichalas Veduvali**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:05.581033Z",
     "start_time": "2019-08-20T22:46:05.556098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Types</th>\n",
       "      <th>Abilities</th>\n",
       "      <th>Tier</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Special Attack</th>\n",
       "      <th>Special Defense</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Next Evolution(s)</th>\n",
       "      <th>Moves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abomasnow</td>\n",
       "      <td>['Grass', 'Ice']</td>\n",
       "      <td>['Snow Warning', 'Soundproof']</td>\n",
       "      <td>PU</td>\n",
       "      <td>90</td>\n",
       "      <td>92</td>\n",
       "      <td>75</td>\n",
       "      <td>92</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Ice Punch', 'Powder Snow', 'Leer', 'Razor Le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name             Types                       Abilities Tier  HP  \\\n",
       "0  Abomasnow  ['Grass', 'Ice']  ['Snow Warning', 'Soundproof']   PU  90   \n",
       "\n",
       "   Attack  Defense  Special Attack  Special Defense  Speed Next Evolution(s)  \\\n",
       "0      92       75              92               85     60                []   \n",
       "\n",
       "                                               Moves  \n",
       "0  ['Ice Punch', 'Powder Snow', 'Leer', 'Razor Le...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:05.591005Z",
     "start_time": "2019-08-20T22:46:05.585022Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(918, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:05.618929Z",
     "start_time": "2019-08-20T22:46:05.593996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>Contest</th>\n",
       "      <th>PP</th>\n",
       "      <th>Power</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pound</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Physical</td>\n",
       "      <td>Tough</td>\n",
       "      <td>35</td>\n",
       "      <td>40</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index   Name    Type  Category Contest  PP Power Accuracy  Generation\n",
       "0      1  Pound  Normal  Physical   Tough  35    40      100           1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf.head(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:05.630898Z",
     "start_time": "2019-08-20T22:46:05.620924Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(728, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:05.648849Z",
     "start_time": "2019-08-20T22:46:05.632893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 12 columns):\n",
      "Name                 918 non-null object\n",
      "Types                918 non-null object\n",
      "Abilities            918 non-null object\n",
      "Tier                 820 non-null object\n",
      "HP                   918 non-null int64\n",
      "Attack               918 non-null int64\n",
      "Defense              918 non-null int64\n",
      "Special Attack       918 non-null int64\n",
      "Special Defense      918 non-null int64\n",
      "Speed                918 non-null int64\n",
      "Next Evolution(s)    918 non-null object\n",
      "Moves                918 non-null object\n",
      "dtypes: int64(6), object(6)\n",
      "memory usage: 86.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:05.663810Z",
     "start_time": "2019-08-20T22:46:05.650845Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 728 entries, 0 to 727\n",
      "Data columns (total 9 columns):\n",
      "Index         728 non-null int64\n",
      "Name          728 non-null object\n",
      "Type          728 non-null object\n",
      "Category      728 non-null object\n",
      "Contest       728 non-null object\n",
      "PP            728 non-null int64\n",
      "Power         728 non-null object\n",
      "Accuracy      728 non-null object\n",
      "Generation    728 non-null int64\n",
      "dtypes: int64(3), object(6)\n",
      "memory usage: 51.3+ KB\n"
     ]
    }
   ],
   "source": [
    "mdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-15T18:28:21.143106Z",
     "start_time": "2019-08-15T18:28:21.121166Z"
    }
   },
   "source": [
    "While it seems like there's no missing data, turns out the string 'None' is used in place of base values. Power and accuracy should also be numeric for modeling. The lists in the pokemon dataframe are also just strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:05.675777Z",
     "start_time": "2019-08-20T22:46:05.665805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Index', 'Name', 'Type', 'Category', 'Contest', 'PP', 'Power',\n",
       "       'Accuracy', 'Generation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:05.946055Z",
     "start_time": "2019-08-20T22:46:05.677773Z"
    }
   },
   "outputs": [],
   "source": [
    "# credit Nicholas\n",
    "df.columns = ['name', 'types', 'abilities', 'tier', 'hp', 'atk', 'def', 'spa', 'spd', 'spe', 'next_evos','moves']\n",
    "\n",
    "#turn the lists into actual lists\n",
    "df['next_evos'] = df.apply(lambda x: eval(x.next_evos), axis=1)\n",
    "df['types'] = df.apply(lambda x: eval(x.types), axis=1)\n",
    "df['abilities'] = df.apply(lambda x: eval(x.abilities), axis=1)\n",
    "df['moves'] = df.apply(lambda x: eval(x.moves), axis=1)\n",
    "\n",
    "df.set_index('name', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:05.959022Z",
     "start_time": "2019-08-20T22:46:05.948050Z"
    }
   },
   "outputs": [],
   "source": [
    "# credit Nicholas\n",
    "mdf.columns = ['index', 'name', 'type', 'category', 'contest', 'pp', 'power', 'accuracy', 'generation']\n",
    "mdf.set_index('index')\n",
    "mdf['power'].replace('None', 0, inplace=True)\n",
    "mdf['accuracy'].replace('None', 100, inplace=True)\n",
    "mdf['power'] = pd.to_numeric(mdf['power'])\n",
    "mdf['accuracy'] = pd.to_numeric(mdf['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Move Names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names of some moves were stored weird as apostrophes were added instead of spaces or dashes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:06.117596Z",
     "start_time": "2019-08-20T22:46:05.961016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Baby'Doll Eyes\", \"Nature's Madness\", \"Mud'Slap\", \"Double'Edge\", \"Trick'or'Treat\", \"Freeze'Dry\", \"Topsy'Turvy\", \"Self'Destruct\", \"Land's Wrath\", \"X'Scissor\", \"Lock'On\", \"Soft'Boiled\", \"Wake'Up Slap\", \"King's Shield\", \"Forest's Curse\", \"Multi'Attack\", \"Will'O'Wisp\", \"U'turn\", \"Power'Up Punch\"}\n"
     ]
    }
   ],
   "source": [
    "# credit Nicholas\n",
    "weird_moves = set()\n",
    "\n",
    "for ind, row in df.iterrows():\n",
    "    for move in row.moves:\n",
    "        if \"'\" in move:\n",
    "            weird_moves.add(move)\n",
    "            \n",
    "print(weird_moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:06.331027Z",
     "start_time": "2019-08-20T22:46:06.119591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"Forest's Curse\", \"King's Shield\", \"Land's Wrath\", \"Nature's Madness\"}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# credit Nicholas\n",
    "weird_moves.remove(\"King's Shield\")\n",
    "weird_moves.remove(\"Forest's Curse\")\n",
    "weird_moves.remove(\"Land's Wrath\")\n",
    "weird_moves.remove(\"Nature's Madness\")\n",
    "\n",
    "df['moves'] = df.apply(\n",
    "    lambda x: [move if move not in weird_moves else move.replace(\"'\", \"-\")\n",
    "                  for move in x.moves],\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "removal_check_set = set()\n",
    "for ind, row in df.iterrows():\n",
    "    for move in row.moves:\n",
    "        if \"'\" in move:\n",
    "            removal_check_set.add(move)\n",
    "\n",
    "removal_check_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some moves are repeated in movesets as they can be learned in multiple ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:06.374908Z",
     "start_time": "2019-08-20T22:46:06.333020Z"
    }
   },
   "outputs": [],
   "source": [
    "df['moves'] = df.apply(lambda x: set(x.moves), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove Struggle Sketch and Z-moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:06.386876Z",
     "start_time": "2019-08-20T22:46:06.376903Z"
    }
   },
   "outputs": [],
   "source": [
    "mdf = mdf[(mdf.pp != 1) | (mdf.name == 'Sketch')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change power of friendship based moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:06.404828Z",
     "start_time": "2019-08-20T22:46:06.388870Z"
    }
   },
   "outputs": [],
   "source": [
    "mdf.loc['Frusuration', 'power'] = 102\n",
    "mdf.loc['Return', 'power'] = 102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check untiered pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:06.434749Z",
     "start_time": "2019-08-20T22:46:06.406823Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>types</th>\n",
       "      <th>abilities</th>\n",
       "      <th>tier</th>\n",
       "      <th>hp</th>\n",
       "      <th>atk</th>\n",
       "      <th>def</th>\n",
       "      <th>spa</th>\n",
       "      <th>spd</th>\n",
       "      <th>spe</th>\n",
       "      <th>next_evos</th>\n",
       "      <th>moves</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Floette-Eternal</th>\n",
       "      <td>[Fairy]</td>\n",
       "      <td>[Flower Veil, Symbiosis]</td>\n",
       "      <td>Limbo</td>\n",
       "      <td>74</td>\n",
       "      <td>65</td>\n",
       "      <td>67</td>\n",
       "      <td>125</td>\n",
       "      <td>128</td>\n",
       "      <td>92</td>\n",
       "      <td>[]</td>\n",
       "      <td>{Helping Hand, Misty Terrain, After You, Hidde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Zeraora</th>\n",
       "      <td>[Electric]</td>\n",
       "      <td>[Volt Absorb]</td>\n",
       "      <td>Limbo</td>\n",
       "      <td>88</td>\n",
       "      <td>112</td>\n",
       "      <td>75</td>\n",
       "      <td>102</td>\n",
       "      <td>80</td>\n",
       "      <td>143</td>\n",
       "      <td>[]</td>\n",
       "      <td>{Volt Switch, Hidden Power, Hone Claws, Grass ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      types                 abilities   tier  hp  atk  def  \\\n",
       "name                                                                         \n",
       "Floette-Eternal     [Fairy]  [Flower Veil, Symbiosis]  Limbo  74   65   67   \n",
       "Zeraora          [Electric]             [Volt Absorb]  Limbo  88  112   75   \n",
       "\n",
       "                 spa  spd  spe next_evos  \\\n",
       "name                                       \n",
       "Floette-Eternal  125  128   92        []   \n",
       "Zeraora          102   80  143        []   \n",
       "\n",
       "                                                             moves  \n",
       "name                                                                \n",
       "Floette-Eternal  {Helping Hand, Misty Terrain, After You, Hidde...  \n",
       "Zeraora          {Volt Switch, Hidden Power, Hone Claws, Grass ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['tier'] == 'Limbo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the dataset was created Zeraora was note released, but since it has been and is in UU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:06.446717Z",
     "start_time": "2019-08-20T22:46:06.437740Z"
    }
   },
   "outputs": [],
   "source": [
    "#Zeraora is now UU\n",
    "df['tier']['Zeraora'] = 'UU'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing Moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scrape failed to add certain pokemon specific moves and event moves. Using bulbapedia we can see which pokemon got the moves in events and can add their evolution lines too to account for all legal competitive movesets. Nicholas didn't do little cup and also left out Celebrate, Hold Hands, and Happy Hour as they have no battle effect. However, Z-Celebrate and Z-Happy Hour are omniboosting moves which are actually used frequently. Hold Hands is too but is not used as often if at all but since it has an identical effect I included it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:06.471650Z",
     "start_time": "2019-08-20T22:46:06.448711Z"
    }
   },
   "outputs": [],
   "source": [
    "# based on code from Nicholas\n",
    "df.loc['Zeraora', 'moves'].add('Plasma Fists')\n",
    "\n",
    "for pok in ['Victini', 'Rayquaza', 'Rayquaza-Mega']:\n",
    "    df.loc[pok, 'moves'].add('V-create')\n",
    "\n",
    "for pok in ['Zygarde', 'Zygarde-10%', 'Zygarde-Complete']:\n",
    "    df.loc[pok, 'moves'].add('Thousand Arrows')\n",
    "    df.loc[pok, 'moves'].add('Thousand Waves')\n",
    "    df.loc[pok, 'moves'].add('Core Enforcer')\n",
    "\n",
    "#adding all evolutions and forms that can also use the move\n",
    "for pok in ['Celebi', 'Serperior', 'Emboar', 'Samurott', 'Mareep', 'Beldum', 'Munchlax', 'Snorlax',\n",
    "           'Metang', 'Metagross', 'Metagross-Mega', 'Flaaffy', 'Ampharos', 'Ampharos-Mega']:\n",
    "    df.loc[pok, 'moves'].add('Hold Back')\n",
    "\n",
    "#only event rockruff can learn celebrate which can only evolve into dusk form\n",
    "for pok in ['Pikachu', 'Raichu', 'Meowth', 'Persian', 'Magikarp', 'Gyarados', 'Gyarados-Mega',\n",
    "           'Delibird', 'Jirachi', 'Greninja', 'Inkay', 'Malamar', 'Munchlax',\n",
    "           'Snorlax', 'Rockruff', 'Lycanroc-Dusk']:\n",
    "    df.loc[pok, 'moves'].add('Celebrate')\n",
    "    \n",
    "for pok in ['Pikachu', 'Charizard', 'Vivillon', 'Raichu', 'Charizard-Mega-X', 'Charizard-Mega-Y']:\n",
    "    df.loc[pok, 'moves'].add('Hold Hands')\n",
    "\n",
    "for pok in ['Bulbasaur', 'Ivysaur', 'Venusaur', 'Venusaur-Mega', 'Charmander',\n",
    "           'Charmeleon', 'Charizard-Mega-X', 'Charizard-Mega-Y',\n",
    "           'Squirtle', 'Wartortle', 'Blastoise', 'Blastoise-Mega', 'Magikarp', 'Gyarados', 'Gyarados-Mega',\n",
    "           'Eevee', 'Vaporeon', 'Jolteon', 'Flareon', 'Espeon', 'Umbreon', 'Ho-Oh', 'Rayquaza', 'Rayquaza-Mega',\n",
    "            'Leafeon', 'Glaceon', 'Sylveon', 'Pikachu', 'Raichu', 'Chansey',\n",
    "            'Victini', 'Comfey', 'Snorlax', 'Aerodactyl', 'Aerodactyl-Mega',\n",
    "            'Vulpix-Alola', 'Ninetales-Alola', 'Exeggutor-Alola', 'Shaymin', 'Shaymin-Sky',\n",
    "            'Meloetta', 'Meloetta-Pirouette']:\n",
    "    df.loc[pok, 'moves'].add('Happy Hour')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates feature for how evolved a pokemon is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:06.898508Z",
     "start_time": "2019-08-20T22:46:06.888536Z"
    }
   },
   "outputs": [],
   "source": [
    "# credit Nicholas\n",
    "def stage_in_evo(n):\n",
    "    # returns number of evolutions before it\n",
    "    #print(df[df['name'] == n]['name'])\n",
    "    bool_arr = df.apply(lambda x: n in x['next_evos'] and (n+'-') not in x['next_evos'], axis=1) #gets index of previous evolution\n",
    "    if ('-' in n and n.split('-')[0] in df.index and n != 'Porygon-Z'): #'-Mega' in n or  \n",
    "        #megas and alternate forms should have same evolutionary stage as their base\n",
    "        return stage_in_evo(n.split('-')[0])\n",
    "    elif not any(bool_arr):\n",
    "        return 1 # if there's nothing before it, it's the first\n",
    "    else:\n",
    "        return 1 + stage_in_evo(df.index[bool_arr][0])\n",
    "\n",
    "def num_evos(n):\n",
    "    if n not in df.index: #checks to ensure valid pokemon\n",
    "        return n\n",
    "    \n",
    "    next_evos = df.loc[n, 'next_evos']\n",
    "    if len(next_evos) > 0: #existence of next_evo\n",
    "        if n in next_evos[0]: # if \"next evo\" is an alternate form\n",
    "            return df.loc[n, 'stage'] #accounting for alternate forms\n",
    "        else:\n",
    "            return num_evos(next_evos[0])\n",
    "    elif '-Mega' in n or (n.split('-')[0] in df.index and n != 'Porygon-Z'): \n",
    "        #this is checking if there is a pokemon with the same root name (e.g. Shaymin vs Shaymin-Sky)\n",
    "        return df.loc[n.split('-')[0], 'stage']\n",
    "    else:\n",
    "        return df.loc[n, 'stage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:45.292461Z",
     "start_time": "2019-08-20T22:46:06.900504Z"
    }
   },
   "outputs": [],
   "source": [
    "df['stage'] = df.apply(lambda x: stage_in_evo(x.name), axis=1)\n",
    "df['num_evos'] = df.apply(lambda x: num_evos(x.name), axis=1)\n",
    "df['evo_progress'] = df['stage']/df['num_evos'] \n",
    "del df['stage']\n",
    "del df['num_evos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternate Form Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates feature if pokemon has an alternate form or mega evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:45.330924Z",
     "start_time": "2019-08-20T22:46:45.295212Z"
    }
   },
   "outputs": [],
   "source": [
    "#based on code from Nicholas, he missed a few\n",
    "df['mega'] = df.apply(lambda x: 1 if '-Mega' in x.name else 0, axis=1)\n",
    "df['alt_form'] = df.apply(lambda x: 1 if ('-' in x.name and \n",
    "                                                x.mega == 0 and \n",
    "                                                '-Alola' not in x.name and \n",
    "                                                x.name.split('-')[0] in df.index and\n",
    "                                                x.name != 'Porygon-Z')\n",
    "                                            else 0,\n",
    "                                            axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expanding on Nicholas' model by adding Little Cup. While little cup is considered a seperate tier and not lower than PU pokemon in LC are weaker than PU mons so when solving as a regression problem it may help to include the tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:45.381796Z",
     "start_time": "2019-08-20T22:46:45.334914Z"
    }
   },
   "outputs": [],
   "source": [
    "df.loc[df.tier == 'OUBL','tier'] = 'Uber'\n",
    "df.loc[df.tier == 'UUBL','tier'] = 'OU'\n",
    "df.loc[df.tier == 'RUBL','tier'] = 'UU'\n",
    "df.loc[df.tier == 'NUBL','tier'] = 'RU'\n",
    "df.loc[df.tier == 'PUBL','tier'] = 'NU'\n",
    "df = df[df['tier'].isin(['Uber', 'OU', 'UU', 'NU', 'RU', 'PU', 'LC'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:45.431655Z",
     "start_time": "2019-08-20T22:46:45.386779Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Uber': 0, 'OU': 1, 'UU': 2, 'RU': 3, 'NU': 4, 'PU': 5, 'LC': 6}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tiers = ['Uber', 'OU', 'UU', 'RU', 'NU', 'PU', 'LC']\n",
    "tier_mapping = {tier:num for num, tier in enumerate(tiers)}\n",
    "df['tier_num'] = df.apply(lambda x: tier_mapping[x.tier], axis=1)\n",
    "tier_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:45.465567Z",
     "start_time": "2019-08-20T22:46:45.435648Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Uber': 47, 'OU': 77, 'UU': 67, 'RU': 72, 'NU': 68, 'PU': 222, 'LC': 265}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tier_size = { t:len(df[df.tier == t]) for t in tiers}\n",
    "tier_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining moves that have a similar use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Condidered adding feature for whether or not pokemon had a hidden ability, but turns out those are actually very common and normally based more on evolution line meaning they likely wouldn't be very predictive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features to add\n",
    "- unique ability\n",
    "- boosting interations \n",
    "- is mythic or legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Move Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:45.528395Z",
     "start_time": "2019-08-20T22:46:45.469559Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['num_moves'] = df.apply(lambda x: len(x['moves']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### BST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Only for plotting purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:45.541361Z",
     "start_time": "2019-08-20T22:46:45.532385Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['bst'] = df['hp'] + df['atk'] + df['def'] + df['spa'] + df['spd'] + df['spe']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T19:19:19.521947Z",
     "start_time": "2019-08-20T19:19:19.508986Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "#### Dual Typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:45.596230Z",
     "start_time": "2019-08-20T22:46:45.544352Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['dual_type'] = df.apply(lambda x: len(x['types']) - 1, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Ability Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:45.631120Z",
     "start_time": "2019-08-20T22:46:45.598210Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['num_abilities'] = df.apply(lambda x: len(x['abilities']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Type Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:45.644085Z",
     "start_time": "2019-08-20T22:46:45.633115Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def coverage(poke):\n",
    "    types = set()\n",
    "    if poke['atk'] > poke['spa']:\n",
    "        if poke['atk'] * .9 > poke['spa']:\n",
    "            offen = 'phys'\n",
    "        else:\n",
    "            offen = 'mix'\n",
    "    elif poke['spa'] > poke['atk']:\n",
    "        if poke['spa'] * .9 > poke['atk']:\n",
    "            offen = 'spec'\n",
    "        else:\n",
    "            offen = 'mix'\n",
    "    else:\n",
    "        offen = 'mix'\n",
    "    \n",
    "    for move in poke['moves']:\n",
    "        if mdf['power'].loc[move] > 0:\n",
    "            if offen == 'mix':\n",
    "                types.add(mdf['type'].loc[move])\n",
    "            elif (offen == 'phys') and (mdf['category'].loc[move] == 'Physical'):\n",
    "                types.add(mdf['type'].loc[move])\n",
    "            elif (offen == 'spec') and (mdf['category'].loc[move] == 'Special'):\n",
    "                types.add(mdf['type'].loc[move])\n",
    "    return len(types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.084907Z",
     "start_time": "2019-08-20T22:46:45.647077Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('Ice Shard', 'occurred at index Abomasnow')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2889\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2890\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2891\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Ice Shard'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-2b297cca7565>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'coverage'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoverage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   6904\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6905\u001b[0m         )\n\u001b[1;32m-> 6906\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6907\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6908\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;31m# compute the result using the series generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-ace022353b8c>\u001b[0m in \u001b[0;36mcoverage\u001b[1;34m(poke)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpoke\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'moves'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mmdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'power'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moffen\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'mix'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                 \u001b[0mtypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'type'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmove\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1410\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1412\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1823\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1824\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1825\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1826\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1827\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[1;31m# but will fail when the index is not present\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;31m# see GH5667\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3736\u001b[0m             \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3737\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3738\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3740\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2890\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2891\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2892\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2893\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2894\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ('Ice Shard', 'occurred at index Abomasnow')"
     ]
    }
   ],
   "source": [
    "df['coverage'] = df.apply(coverage, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Banned Ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.127794Z",
     "start_time": "2019-08-20T22:46:11.055Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def has_banned(poke):\n",
    "    banned = {'Drought', 'Sand Stream', 'Sand Veil', 'Snow Cloak', 'Snow Warning'}\n",
    "    result = 0\n",
    "    for abil in banned:\n",
    "        if abil in poke['abilities']:\n",
    "            result = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.129788Z",
     "start_time": "2019-08-20T22:46:11.064Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['ban_abil'] = df.apply(has_banned, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Weaknesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Will double count a 4x weakness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.131782Z",
     "start_time": "2019-08-20T22:46:11.606Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tdf.set_index('atck', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.134773Z",
     "start_time": "2019-08-20T22:46:11.613Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def weakness(poke):\n",
    "    weak = []\n",
    "    res = []\n",
    "    for def_t in poke['types']:\n",
    "        for atk_t in tdf.index:\n",
    "            if tdf[def_t][atk_t] == 2.0:\n",
    "                weak.append(atk_t)\n",
    "            if (tdf[def_t][atk_t] == 0.5) or (tdf[def_t][atk_t] == 0.0):\n",
    "                res.append(atk_t)\n",
    "    for w in weak:\n",
    "        if w in res:\n",
    "            weak.remove(w)\n",
    "            res.remove(w)\n",
    "    return len(weak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.136768Z",
     "start_time": "2019-08-20T22:46:11.618Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['weakness'] = df.apply(weakness, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Resistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.137768Z",
     "start_time": "2019-08-20T22:46:11.965Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def resistance(poke):\n",
    "    weak = []\n",
    "    res = []\n",
    "    immunity = {'Sap Sipper', 'Levitate', 'Lightning Rod', 'Flash Fire', 'Volt Absorb', 'Water Absorb', 'Thick Fat',\n",
    "                'Storm Drain', 'Motor Drive', 'Water Bubble', 'Soundproof'} #might be more\n",
    "    for def_t in poke['types']:\n",
    "        for atk_t in tdf.index:\n",
    "            if tdf[def_t][atk_t] == 2.0:\n",
    "                weak.append(atk_t)\n",
    "            if (tdf[def_t][atk_t] == 0.5) or (tdf[def_t][atk_t] == 0.0):\n",
    "                res.append(atk_t)\n",
    "    for w in weak:\n",
    "        if w in res:\n",
    "            weak.remove(w)\n",
    "            res.remove(w)\n",
    "    for abil in poke['abilities']:\n",
    "        if abil in immunity:\n",
    "            res += 'Ability'\n",
    "    return len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.139761Z",
     "start_time": "2019-08-20T22:46:11.972Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['resist'] = df.apply(resistance, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.141760Z",
     "start_time": "2019-08-20T22:46:12.235Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df['tier_num'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Baselne is 32%, but unfortunately there are fewer pokemon in higher tiers, so classes are unbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.143751Z",
     "start_time": "2019-08-20T22:46:12.683Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# credit Nicholas\n",
    "stats_df = df[['tier', 'tier_num', 'hp', 'atk', 'def', 'spa', 'spd', 'spe']]\n",
    "stats_df = stats_df.reset_index()\n",
    "stats_df = stats_df.melt(id_vars=['name', 'tier', 'tier_num']).sort_values('tier_num', ascending=True)\n",
    "stats_df.columns = ('name', 'Tier', 'tier_num', 'Stat', 'Value')\n",
    "#stats_df.Value = pd.to_numeric(stats_df.Value)\n",
    "\n",
    "sns.set_context('talk')\n",
    "fig, ax = plt.subplots(1,2, figsize=(25,8), gridspec_kw = {'width_ratios':[3, 1]})\n",
    "g = sns.boxplot(data=stats_df, x=\"Stat\", y=\"Value\", order=['hp', 'atk', 'def', 'spa', 'spd', 'spe'],\n",
    "                hue=\"Tier\", palette=\"muted\", ax=ax[0])\n",
    "g2 = sns.boxplot(data=df, x='tier', y='bst', order=tiers, palette=\"muted\", ax=ax[1])\n",
    "#g2=sns.factorplot(x=\"Tier\", y=\"Average\", hue_order=['bst'],hue=\"Stat\", data=temp2,\n",
    "#                   kind=\"bar\", palette=\"muted\", aspect=1.5,  ax=ax[1])\n",
    "ax[0].set(xlabel='Tier', ylabel='Stat Average', title='Distribution of Stats by Tier')\n",
    "ax[1].set(xlabel='Tier', ylabel='BST Average', title='Distribution of BST by Tier');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Strong seperation between LC and Ubers tiers for msot stats but less seperation with middling tiers. Likely because a pokemon generally excels in only one or two areas and is weaker in others, so base stat total shows more seperation with ubers and little cup but not as much in middle. Little cup is unevolved pokemon and ubers is mostly legendary which explains the stat differences. Suggests that moves and abilities are more important at differentiating middle tiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looking only at their highest stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.147740Z",
     "start_time": "2019-08-20T22:46:13.284Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# credit Nicholas\n",
    "stats_df2 = df.loc[:, ['tier', 'hp', 'atk', 'def', 'spa', 'spd', 'spe']].reset_index().set_index(['name','tier'])\n",
    "aggregates = {('Top {} Avg'.format(v),(lambda x, v=v: np.mean(np.sort(x)[::-1][:v]))) for v in range(1, 7)} \n",
    "stats_df2 = stats_df2.stack().groupby(['name','tier']).agg(aggregates).stack().reset_index()\n",
    "stats_df2.columns = ['Name', 'Tier', 'Average', 'Stat Average']\n",
    "\n",
    "plt.subplots(figsize=(17,7))\n",
    "sns.boxplot(data=stats_df2.sort_values('Average'), hue='Tier', y='Stat Average', x='Average', \n",
    "            hue_order=tiers, palette='muted').set_title('Average of Top x Stats by Tier');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Since pokemon tend to excel in only 1-3 areas it makes sense to assume that hihg tiered pokemon have a higher highest few stats. While there does seem to be a linear relationship it fails to differentiate suggesting that balance is important too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Roles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pokemon tend to have roles that they serve on a team, ex a physical sweeper is generally a fast pokemon with high attack. Nicholas chose not to include roles in anyway as they are present in every tier and there are pokemon in all tiers will have low stats in those areas. I think this can be accounted for with interaton terms. Continuing with the phys sweeper example a non sweeper would have a low atk * spe, a NU mon would have a decent score, and an uber an even higher one. So the score is only predictive if above a certain level which suggests relu in a neural network may pick up on this feature easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.150731Z",
     "start_time": "2019-08-20T22:46:14.097Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stats_df = df[['tier', 'hp', 'atk', 'def', 'spa', 'spd', 'spe']] #'tier_num', , 'bst'\n",
    "sns.pairplot(stats_df, hue='tier', hue_order=list(reversed(tiers)), plot_kws={'s':25},\n",
    "               palette=list(reversed(sns.color_palette('muted'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Some common roles and the interactions that would determine success of a pokemon in that role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.151728Z",
     "start_time": "2019-08-20T22:46:14.346Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stats_df['spe^2'] = stats_df['spe'] * stats_df['spe']\n",
    "stats_df['atk^2'] = stats_df['atk'] * stats_df['atk']\n",
    "stats_df['def^2'] = stats_df['def'] * stats_df['def']\n",
    "stats_df['hp^2'] = stats_df['hp'] * stats_df['hp']\n",
    "stats_df['spa^2'] = stats_df['spa'] * stats_df['spa']\n",
    "stats_df['spd^2'] = stats_df['spd'] * stats_df['spd']\n",
    "\n",
    "stats_df['phy_sweep'] = stats_df['atk'] * stats_df['spe']\n",
    "stats_df['spc_sweep'] = stats_df['spa'] * stats_df['spe']\n",
    "stats_df['mixed_sweep'] = stats_df['atk'] * stats_df['spe'] * stats_df['spa']\n",
    "stats_df['phy_wall'] = stats_df['def'] * stats_df['hp']\n",
    "stats_df['spc_wall'] = stats_df['spd'] * stats_df['hp']\n",
    "stats_df['mixed_sweep'] = stats_df['def'] * stats_df['spd'] * stats_df['hp']\n",
    "stats_df['phy_check'] = stats_df['atk'] * stats_df['def']\n",
    "stats_df['spc_check'] = stats_df['spa'] * stats_df['spd']\n",
    "stats_df['phy_bulk'] = stats_df['atk'] * stats_df['def'] * stats_df['hp']\n",
    "stats_df['spc_bulk'] = stats_df['spa'] * stats_df['spd'] * stats_df['hp']\n",
    "stats_df['bal'] = stats_df['spa'] * stats_df['spd'] * stats_df['hp'] * stats_df['spe'] * stats_df['atk'] * stats_df['def']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.154725Z",
     "start_time": "2019-08-20T22:46:14.352Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "stats_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.156715Z",
     "start_time": "2019-08-20T22:46:14.358Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sns.boxplot(data=stats_df,x ='tier', y='spe', hue='tier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.158710Z",
     "start_time": "2019-08-20T22:46:14.723Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# credit Nicholas\n",
    "type_set = set()\n",
    "\n",
    "for ind, row in df.iterrows():\n",
    "    type_set |= set(row.types) #for use later\n",
    "\n",
    "type_df_temp = df.copy()\n",
    "type_df_temp['type 1'] = type_df_temp.apply(lambda x: sorted(x['types'])[0], axis=1)\n",
    "type_df_temp['type 2'] = type_df_temp.apply(lambda x: sorted(x['types'])[-1], axis=1) #if a pokemon has a single type, type 2 = type 1\n",
    "\n",
    "type_df = type_df_temp[['type 2', 'type 1']].groupby(['type 2', 'type 1']).size().reset_index()\n",
    "type_df.columns = ['type 1', 'type 2', 'count']\n",
    "type_pivoted_df = type_df.pivot('type 1', 'type 2', 'count')\n",
    "\n",
    "plt.subplots(figsize=(8,8))\n",
    "sns.heatmap(type_pivoted_df, annot=True, square=True, cmap='Blues', linecolor='grey', linewidths='0.05')\n",
    "plt.gca().set(title='Frequency of Type Combinations');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.162699Z",
     "start_time": "2019-08-20T22:46:14.732Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# credit Nicholas\n",
    "\n",
    "#Get individual counts of type1 and type 2\n",
    "type1_count = type_df_temp[['tier', 'type 1']].groupby(['tier', 'type 1']).size().reset_index()\n",
    "type2_count = type_df_temp[['tier', 'type 2']].groupby(['tier', 'type 2']).size().reset_index()\n",
    "type1_count.columns=['tier', 'type', 'count1']\n",
    "type2_count.columns=['tier', 'type', 'count2']\n",
    "\n",
    "#Get overall type frequency per tier\n",
    "type_count = pd.merge(type1_count, type2_count, on=['tier', 'type'], how='outer')\n",
    "type_count.fillna(value=0, inplace=True)\n",
    "type_count['count'] = type_count['count1'] + type_count['count2']\n",
    "type_count_ind = type_count.set_index(['tier','type'])\n",
    "type_count['count'] = type_count.apply(lambda x: x['count']/np.sum(type_count_ind.loc[x['tier'], 'count'])\n",
    "                                      , axis=1) # /np.sum(type_count_ind2.loc[x['tier'], 'count'])\n",
    "\n",
    "#Format Table and Sort rows\n",
    "type_count = type_count[['tier','type','count']]\n",
    "type_count = type_count.set_index(['tier','type']).unstack()['count']\n",
    "type_count['tier_nums'] = type_count.apply(lambda x: tier_mapping[x.name],axis=1)\n",
    "type_count = type_count.sort_values(by='tier_nums', ascending=False)\n",
    "del type_count['tier_nums']\n",
    "\n",
    "colors = [(104,144,240), (184,184,208), (184,160,56), (248,88,136), \n",
    "          (160,64,160), (168,168,120), (152,216,216), (224,192,104), \n",
    "          (120,200,80), (112,88,152), (168,144,240), (240,128,48), \n",
    "          (192,48,40), (238,153,172), (248,208,48), (112,56,248), \n",
    "          (112,88,72), (168,184,32)]\n",
    "colors = [tuple(i/255.0 for i in c)\n",
    "               for c in colors]\n",
    "#Plit\n",
    "type_count.plot.bar(stacked=True, title='Distribution of dfmon Types in Tiers', \n",
    "                     legend=False, figsize=(12, 7), sort_columns=True, width=0.8,\n",
    "                    color=reversed(colors))\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5), handles=handles[::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Definitely more dragons, psychic and steel pokemon in higher tiers. Fewer rock, and grass which are considered 3 of the weakest types in the game. Dragon is common among legendaries and is the best physically offensice type whereas psychic is the best specially offensive. Steel is the best defensive type. Bug is also less frequent in higher tiers as most bug pokemon are weak not the typing being bad. This also explains water which is considered the best overall type in the game; there are alot of very weak fish pokemon but the stronger water pokemon are in UU mostly, which is a tier dominated by rain teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.164694Z",
     "start_time": "2019-08-20T22:46:15.263Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# credit Nicholas\n",
    "mdf.set_index('name', inplace=True)\n",
    "\n",
    "mdf['uber count'] = 0\n",
    "mdf['ou count'] = 0\n",
    "mdf['uu count'] = 0\n",
    "mdf['ru count'] = 0\n",
    "mdf['nu count'] = 0\n",
    "mdf['pu count'] = 0\n",
    "mdf['lc count'] = 0\n",
    "\n",
    "for ind, row in df.iterrows():\n",
    "    for move in row.moves:\n",
    "        mdf.loc[move, row.tier.lower() + ' count'] += 1\n",
    "        \n",
    "mdf['count'] = mdf['uber count'] + mdf['ou count'] + mdf['uu count'] + mdf['ru count'] + mdf['nu count'] + mdf['pu count'] + mdf['lc count']\n",
    "#mdf = mdf.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Signiture Moves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Pokemon with signiture move or exclusive moves are generally fully evoled or legendary. These moves are also generally very strong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.166690Z",
     "start_time": "2019-08-20T22:46:15.886Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# credit Nicholas\n",
    "for t in tiers:\n",
    "    mdf[t + ' %'] = mdf[t.lower() + ' count']/tier_size[t]*100\n",
    "\n",
    "exclusives = mdf[mdf['count'] <= 3][[t + ' %' for t in tiers]].unstack().reset_index()\n",
    "del exclusives['name']\n",
    "exclusives.columns=['Tier', 'Percent of Pokemon that Learn a Given Exclusive Move']\n",
    "exclusives['Tier'] = exclusives.apply(lambda x: x['Tier'].split(' ')[0], axis=1)\n",
    "\n",
    "normals = mdf.copy()[[t + ' %' for t in tiers]].unstack().reset_index()\n",
    "del normals['name']\n",
    "normals.columns=['Tier', 'Percent of Pokemon that Learn a Given Move']\n",
    "normals['Tier'] = normals.apply(lambda x: x['Tier'].split(' ')[0], axis=1)\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize=(25,8))\n",
    "sns.boxplot(data=exclusives, x='Tier', y='Percent of Pokemon that Learn a Given Exclusive Move', palette='muted', ax=ax[0])\n",
    "sns.boxplot(data=normals, x='Tier', y='Percent of Pokemon that Learn a Given Move', palette='muted', ax=ax[1])\n",
    "ax[0].set(title='Distribution for Exclusive Moves among the Tiers')\n",
    "ax[1].set(title='Distribution for All Move samong the Tiers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Clearly OU and Ubers have the most unique moves, but PU is next surpringly not sure why that might be, could be becuase of evolution line exclusives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.168684Z",
     "start_time": "2019-08-20T22:46:16.140Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "exclusive_moves = set(mdf[mdf['count'] <= 3].index)\n",
    "df['num_exclusive'] = df.apply(lambda x: len(exclusive_moves.intersection(x['moves'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.170681Z",
     "start_time": "2019-08-20T22:46:16.150Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# based on code from Nicholas adapted to add LC\n",
    "edf = df.loc[:, ['tier', 'tier_num', 'num_exclusive']]\n",
    "edf['indicator'] = edf.apply(lambda x: 1 if x.num_exclusive > 0 else 0, axis=1)\n",
    "edf = edf.pivot_table(values='indicator', index=['tier', 'tier_num'], columns='num_exclusive', fill_value=0, aggfunc=np.count_nonzero)\n",
    "edf.reset_index(inplace=True)\n",
    "edf.columns = ['Tier', 'tier_num'] + [str(i) for i in range(5)]\n",
    "edf.sort_values('tier_num', inplace=True)\n",
    "del edf['tier_num']\n",
    "del edf['0']\n",
    "\n",
    "for i in range(1,  5):\n",
    "    edf[str(i)] = edf.apply(lambda x: x[str(i)]/tier_size[x['Tier']]*100, axis=1)\n",
    "\n",
    "edf.set_index('Tier').plot.barh(stacked=True, color=sns.color_palette('muted'), figsize=(10, 5))\n",
    "plt.gca().set(title='% of Pokemon by Tier that Learn 1+ Exclusive Moves')\n",
    "plt.legend(title='# Exclusives')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Strongest Moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.173674Z",
     "start_time": "2019-08-20T22:46:16.419Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# adpated from code by Nicholas he removed attack lowering moves but these as actually more useful and used\n",
    "# frequently in competitive play\n",
    "# chose to remove self destruct moves even tho they see play too because they could skew the feature\n",
    "\n",
    "highest_moves = []\n",
    "#we do not want to count moves with recharge as half power,\n",
    "#as they waste a turn and are not used commonly used in competitive\n",
    "moves_w_recharge = {'Blast Burn', 'Frenzy Plant', 'Giga Impact', 'Hydro Cannon',\n",
    "                      'Hyper Beam', 'Prismatic Laster', 'Roar of Time', 'Rock Wrecker',\n",
    "                      'Shadow Half'}\n",
    "\n",
    "#these moves cause the user to fiant, so they will not be included\n",
    "self_destroy = {'Explosion', 'Self-Destruct'}\n",
    "\n",
    "def get_max_power(moves, typ, category, min_acc):\n",
    "    moves = list(set(moves) - moves_w_recharge - self_destroy)\n",
    "    highest = np.max([mdf.loc[m, 'power'] if mdf.loc[m, 'category'] == category\n",
    "                                          and mdf.loc[m, 'accuracy'] >= min_acc \n",
    "                                          and mdf.loc[m, 'type'] == typ\n",
    "                                       else 0\n",
    "                        for m in moves])\n",
    "    return highest\n",
    "\n",
    "def get_primary(x):\n",
    "    atk_higher = x.atk >= x.spa\n",
    "    spa_higher = x.spa >= x.atk\n",
    "    candidates = []\n",
    "    for t in x.types:\n",
    "        candidates.append(x[t+'_physical'] if x.atk >= x.spa else 0)\n",
    "        candidates.append(x[t+'_special'] if x.atk <= x.spa else 0)\n",
    "    return np.max(candidates)\n",
    "\n",
    "for t in tqdm_notebook(type_set):\n",
    "    df[t+'_physical'] = df.apply(lambda x: get_max_power(x.moves, t, 'Physical', 85), axis=1)\n",
    "    df[t+'_special'] = df.apply(lambda x: get_max_power(x.moves, t, 'Special', 85), axis=1)\n",
    "    highest_moves += [t+'_physical', t+'_special']\n",
    "\n",
    "df['primary_attack'] = df.apply(get_primary, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.175665Z",
     "start_time": "2019-08-20T22:46:16.425Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "offensive_pokemon = df.apply(lambda x: max(x['atk'], x['spa']) > max(x['def'], x['spd']), axis=1)\n",
    "a=sns.boxplot(data=df[offensive_pokemon], x='tier', y='primary_attack', palette='muted', order=tiers)\n",
    "a.set(title='Distribution of Primary Attack Power for Offensive Pokemon');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This feature generated by Nicholas isn't very predictive, but fails to take the attack power of the pokemon into account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.177659Z",
     "start_time": "2019-08-20T22:46:16.860Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "move_set = set()\n",
    "\n",
    "for ind, row in df.iterrows():\n",
    "    move_set |= row.moves\n",
    "\n",
    "move_df = df[['tier', 'tier_num']]\n",
    "\n",
    "for m in move_set:\n",
    "    move_df[m] = df.apply(lambda x: 1 if m in x.moves else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.179653Z",
     "start_time": "2019-08-20T22:46:16.866Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# credit Nicholas\n",
    "priority = {'Fake Out', 'Extreme Speed', 'Feint', 'Aqua Jet', 'Bullet Punch', 'Ice Shard', 'Accelerock'\n",
    "            'Mach Punch', 'Shadow Sneak', 'Sucker Punch', 'Vacuum Wave', 'Water Shuriken'}\n",
    "df['priority_stab'] = df.apply(lambda x: 1 if any([(mdf.loc[m, 'type'] in x.types) \n",
    "                                                   for m in x.moves.intersection(priority)]) else 0,\n",
    "                               axis=1)\n",
    "recovery = {'Heal Order', 'Milk Drink', 'Moonlight', 'Morning Sun', 'Purify', 'Recover',\n",
    "            'Roost', 'Shore Up', 'Slack Off', 'Soft-Boiled', 'Synthesis', 'Strength Sap', 'Wish'}\n",
    "df['recovery_move'] = df.apply(lambda x: 1 if len(x.moves.intersection(recovery)) > 0 else 0, axis=1)\n",
    "stat_increasing = {'Coil': 3, 'Hone Claws': 2, 'Belly Drum': 6, 'Bulk Up': 2, 'Clangorous Soulblaze': 4, \n",
    "                   'Dragon Dance': 2, 'Shell Smash': 4, 'Shift Gear': 3, 'Swords Dance': 2, 'Work Up': 2,\n",
    "                   'Cosmic Power': 2,  'Defend Order': 2, 'Calm Mind': 2, 'Geomancy': 6, \n",
    "                   'Nasty Plot': 2, 'Quiver Dance': 3, 'Tail Glow': 3, 'Agility': 2, 'Automize': 2, 'Rock Polish': 2}\n",
    "\n",
    "\n",
    "df['stat_inc_move'] = df.apply(lambda x: np.max([0]+[stat_increasing[v] for v in x.moves.intersection(stat_increasing)]), axis=1)\n",
    "\n",
    "atk_inc_ability = {'Huge Power', 'Pure Power'}\n",
    "df['atk_inc_ability'] = df.apply(lambda x: 1 if len(set(x.abilities).intersection({'Huge Power', 'Pure Power'})) > 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Abilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Bad Abilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T21:01:13.619002Z",
     "start_time": "2019-08-20T21:01:13.613440Z"
    },
    "hidden": true
   },
   "source": [
    "Creates a feauture for pokemon that have a bad ability despite good stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.181649Z",
     "start_time": "2019-08-20T22:46:17.672Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# credit Nicholas\n",
    "from collections import defaultdict\n",
    "a_dict = defaultdict(int)\n",
    "\n",
    "for ind, row in df.iterrows():\n",
    "    for ability in row.abilities:\n",
    "        a_dict[(ability, row.tier + ' count')] += 1\n",
    "\n",
    "\n",
    "adf = pd.DataFrame(pd.Series(a_dict)).reset_index() #(columns=(['name'] + [t + ' Count' for t in tiers]))\n",
    "adf.columns=['name', 'tier', 'count']\n",
    "adf = adf.pivot_table(values='count', index='name', columns='tier', fill_value=-0)\n",
    "adf['count'] = sum(adf[t + ' count'] for t in tiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.183643Z",
     "start_time": "2019-08-20T22:46:17.678Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bad_abilities = {'Comatose', 'Defeatist', 'Emergency Exit', 'Slow Start', 'Truant', 'Wimp Out', 'Stall'}\n",
    "df['bad_ability'] = df.apply(lambda x: 1 if len(set(x['abilities']).intersection(bad_abilities)) == len(x['abilities'])\n",
    "                                       else 0, axis=1)\n",
    "df[df.bad_ability == 1];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Unique abilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## Evolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Creates feauture for how evolved a pokemon is, could be very useful considering how evolve pokemon are always stronger and evolution is even a factor in determining little cup pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.184640Z",
     "start_time": "2019-08-20T22:46:18.621Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# credit Nicholas\n",
    "evodf = df.loc[:, ['tier', 'tier_num', 'evo_progress']]\n",
    "evodf['count'] = evodf.apply(lambda x: 1/tier_size[x.tier], axis=1) \n",
    "#so when we sum everything up, values will be normalized to tier size\n",
    "evodf = evodf.pivot_table(values='count', index=['tier', 'tier_num'], columns='evo_progress', fill_value=0, aggfunc=np.sum)\n",
    "evodf = evodf.sort_values('tier_num').reset_index()\n",
    "del evodf['tier_num']\n",
    "evodf.columns = ['Tier', '0.33','0.50', '0.67', '1.00']\n",
    "evodf.set_index('Tier', inplace=True)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "evodf.plot.barh(stacked=True, color=sns.color_palette('muted')[3::-1], figsize=(12, 3), \n",
    "                title='Distribution of Evolutionary Stages by Tier')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5),title='Evolutionary Progress');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Little cup pokemon are very easily distinguished by their evolutionary stage. but after that it becomes a little more complicated. Regardless this feature is likely very useful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.186639Z",
     "start_time": "2019-08-20T22:46:19.297Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# credit Nicholas\n",
    "altdf = df.loc[:, ['tier', 'tier_num', 'mega', 'alt_form']]\n",
    "altdf['mega'] = altdf.apply(lambda x: x.mega/tier_size[x.tier], axis=1) \n",
    "altdf['alt_form'] = altdf.apply(lambda x: x.mega/tier_size[x.tier], axis=1)\n",
    "altdf['normal'] = altdf.apply(lambda x: 1/tier_size[x.tier] if x['mega'] == 0 and x['alt_form'] == 0 else 0, axis=1)\n",
    "#so when we sum everything up, values will be normalized to tier size\n",
    "\n",
    "#altdf = altdf.pivot_table(values='count', index=['tier', 'tier_num'], columns='evo progress', fill_value=0, aggfunc=np.sum)\n",
    "altdf = altdf.groupby(['tier', 'tier_num']).agg(np.sum).reset_index().sort_values('tier_num')\n",
    "del altdf['tier_num']\n",
    "altdf.columns = ['Tier', 'Mega', 'Alternate', 'Base']\n",
    "altdf.set_index('Tier', inplace=True)\n",
    "\n",
    "plt.figure(figsize=(20, 4))\n",
    "altdf.plot.barh(stacked=True, color=sns.color_palette('muted')[2::-1], figsize=(12, 3), \n",
    "                title='Distribution of Forms by Tier')\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5),title='Form');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Clearly Mega pokemon place in higher tiers as do alternate forms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.188631Z",
     "start_time": "2019-08-20T22:46:19.573Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# credit Nicholas\n",
    "alt = df.loc[(df['alt_form'] == 1), ['tier_num']]\n",
    "mega = df.loc[(df['mega'] == 1), ['tier_num']]\n",
    "alt_base = df.loc[set(map(lambda x: x.split('-')[0], alt.index)), ['tier_num']]\n",
    "mega_base = df.loc[set(map(lambda x: x.split('-')[0], mega.index)), ['tier_num']]\n",
    "\n",
    "alt['Form'] = 'Alternate'\n",
    "mega['Form'] = 'Mega'\n",
    "alt_base['Form'] = 'Alternate Base'\n",
    "mega_base['Form'] = 'Mega Base'\n",
    "\n",
    "combined = pd.concat([mega, mega_base, alt, alt_base])\n",
    "combined.columns = ['Tier', 'Form']\n",
    "plt.gca().invert_yaxis()\n",
    "plt.gca().set(title='Distribution of Forms among Tiers', yticklabels=['']+tiers)\n",
    "sns.boxplot(data=combined, x='Form', y='Tier', palette='muted');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T19:38:00.054678Z",
     "start_time": "2019-08-20T19:37:59.985860Z"
    }
   },
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.190628Z",
     "start_time": "2019-08-20T22:46:19.981Z"
    }
   },
   "outputs": [],
   "source": [
    "#To do this efficiently, we will simply create a dictionary of moves and abilities.\n",
    "#We will map all of them to themselves to start, then alter the variations\n",
    "ability_set = set()\n",
    "move_set = set()\n",
    "type_set = set()\n",
    "\n",
    "for ind, row in df.iterrows():\n",
    "    ability_set |=  set(row.abilities) #union\n",
    "    move_set |= row.moves\n",
    "    type_set |= set(row.types)\n",
    "\n",
    "ability_dict = {s:{s} for s in ability_set if s not in {\n",
    "                   'Battle Armor', 'White Smoke', 'Full Metal Body', 'Solid Rock', 'Prism Armor', 'Gooey', \n",
    "                   'Magnet Pull', 'Shadow Tag', 'Inner Focus', 'Insomnia', 'Vital Spirit', 'Limber', 'Magma Armor', \n",
    "                  'Own Tempo', 'Oblivious', 'Water Veil', 'Sweet Veil', 'Aroma Veil', 'Hyper Cutter', 'Big Pecks',\n",
    "                   'Triage', 'Heatproof', 'Iron Barbs', 'Quick Feet', 'Flare Boost', 'Toxic Boost'\n",
    "               }} #dictionary of sets\n",
    "\n",
    "#We will not consolidate weather-variations because the viability of various weather conditions varies\n",
    "\n",
    "ability_dict['Shell Armor'].add('Battle Armor')\n",
    "ability_dict['Clear Body'] |= {'White Smoke', 'Full Metal Body'}\n",
    "ability_dict['Filter'] |= {'Solid Rock', 'Prism Armor'}\n",
    "ability_dict['Tangling Hair'].add('Gooey')\n",
    "\n",
    "# Below are cases where the abilities aren't identical, but close enough\n",
    "ability_dict['Arena Trap'] |= {'Magnet Pull', 'Shadow Tag'} \n",
    "ability_dict['Guts'] |= {'Quick Feet', 'Flare Boost', 'Toxic Boost'} # Marvel scale is excluded from this because it boosts defense\n",
    "ability_dict['Immunity'] |= {'Inner Focus', 'Insomnia', 'Vital Spirit', 'Limber', 'Magma Armor', \n",
    "          'Own Tempo', 'Oblivious', 'Water Veil', 'Sweet Veil', 'Aroma Veil'}\n",
    "ability_dict['Keen Eye'] |= {'Hyper Cutter', 'Big Pecks'} \n",
    "ability_dict['Prankster'].add('Triage')\n",
    "ability_dict['Thick Fat'].add('Heatproof')\n",
    "ability_dict['Rough Skin'].add('Iron Barbs')\n",
    "#water absorb and dry skin?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.191622Z",
     "start_time": "2019-08-20T22:46:20.272Z"
    }
   },
   "outputs": [],
   "source": [
    "entry_hazards = {'Toxic Spikes', 'Stealth Rock', 'Spikes'}\n",
    "df['entry_hazards'] = df.apply(lambda x: 1 if len(x.moves.intersection(entry_hazards)) > 0 else 0, axis=1)\n",
    "\n",
    "hazard_clear = {'Rapid Spin'} #we may later exclude/add defog \n",
    "df['hazard_clear'] = df.apply(lambda x: 1 if len(x.moves.intersection(hazard_clear)) > 0 else 0, axis=1)\n",
    "\n",
    "phazing_moves = {'Roar', 'Whirlwind', 'Dragon Tail', 'Circle Throw'}\n",
    "df['phazing_moves'] = df.apply(lambda x: 1 if len(x.moves.intersection(phazing_moves)) > 0 else 0, axis=1)\n",
    "\n",
    "switch_attack = {'U-turn', 'Volt Switch'}\n",
    "df['switch_attack'] = df.apply(lambda x: 1 if len(x.moves.intersection(switch_attack)) > 0 else 0, axis=1)\n",
    "\n",
    "#strong moves (>65 power) that have a >30% chance of causing side effects with an accuracy over 85%\n",
    "high_side_fx_prob = {'Steam Eruption','Sludge Bomb', 'Lava Plume', 'Iron Tail', 'Searing Shot', \n",
    "                     'Rolling Kick', 'Rock Slide', 'Poison Jab', 'Muddy Water', 'Iron Head',\n",
    "                    'Icicle Crash', 'Headbutt', 'Gunk Shot', 'Discharge', 'Body Slam', 'Air Slash'}\n",
    "df['high_side_fx_prob'] = df.apply(lambda x: 1 if len(x.moves.intersection(high_side_fx_prob)) > 0 else 0, axis=1)\n",
    "\n",
    "constant_dmg = {'Seismic Toss', 'Night Shade'}\n",
    "df['constant_dmg'] = df.apply(lambda x: 1 if len(x.moves.intersection(constant_dmg)) > 0 else 0, axis=1)\n",
    "\n",
    "trapping_move = {'Mean Look', 'Block', 'Spider Web'}\n",
    "df['trapping_move'] = df.apply(lambda x: 1 if len(x.moves.intersection(trapping_move)) > 0 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.193617Z",
     "start_time": "2019-08-20T22:46:20.278Z"
    }
   },
   "outputs": [],
   "source": [
    "stats = ['hp', 'atk', 'def', 'spa', 'spd', 'spe'] #bst excluded\n",
    "forms = ['evo_progress', 'mega', 'alt_form']\n",
    "moves_based = ['num_moves','num_exclusive', 'bad_ability', 'stat_inc_move', 'recovery_move', 'priority_stab',\n",
    "              'entry_hazards', 'hazard_clear', 'phazing_moves', 'switch_attack', 'high_side_fx_prob', 'constant_dmg',\n",
    "              'trapping_move']\n",
    "ability_based = ['atk_inc_ability', 'bad_ability']\n",
    "\n",
    "df_y = df.loc[:, 'tier_num']\n",
    "df_x = df.loc[:, stats + forms + moves_based + ability_based + highest_moves] \n",
    "#remove bst because it is just a sum of the individual stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.196616Z",
     "start_time": "2019-08-20T22:46:20.284Z"
    }
   },
   "outputs": [],
   "source": [
    "ability_set -= atk_inc_ability | bad_abilities | set(adf[adf['count'] <= 2].index)\n",
    "move_set -=  stat_increasing.keys() | recovery | priority | set(mdf[(mdf['count'] <= 3) | (mdf['power'] > 0)].index) \\\n",
    "             | entry_hazards | hazard_clear | phazing_moves | switch_attack | high_side_fx_prob | constant_dmg | trapping_move\n",
    "\n",
    "for a in ability_dict.keys():\n",
    "    df_x[a] = df.apply(lambda x: 1 if len(ability_dict[a].intersection(x.abilities))>0 else 0, axis = 1)\n",
    "for m in move_set:\n",
    "    df_x[m] = df.apply(lambda x: 1 if m in x.moves else 0, axis = 1)\n",
    "for t in type_set:\n",
    "    df_x[t] = df.apply(lambda x: 1 if t in x.types else 0, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom interation terms based on roles that pokemon commonly serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.199606Z",
     "start_time": "2019-08-20T22:46:20.615Z"
    }
   },
   "outputs": [],
   "source": [
    "df_x['phy_sweep'] = df_x['atk'] * df_x['spe']\n",
    "df_x['spc_sweep'] = df_x['spa'] * df_x['spe']\n",
    "df_x['mixed_sweep'] = df_x['atk'] * df_x['spe'] * df_x['spa']\n",
    "df_x['phy_wall'] = df_x['def'] * df_x['hp']\n",
    "df_x['spc_wall'] = df_x['spd'] * df_x['hp']\n",
    "df_x['mixed_sweep'] = df_x['def'] * df_x['spd'] * df_x['hp']\n",
    "df_x['phy_check'] = df_x['atk'] * df_x['def']\n",
    "df_x['spc_check'] = df_x['spa'] * df_x['spd']\n",
    "df_x['phy_bulk'] = df_x['atk'] * df_x['def'] * df_x['hp']\n",
    "df_x['spc_bulk'] = df_x['spa'] * df_x['spd'] * df_x['hp']\n",
    "df_x['bal'] = df_x['spa'] * df_x['spd'] * df_x['hp'] * df_x['spe'] * df_x['atk'] * df_x['def']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.201595Z",
     "start_time": "2019-08-20T22:46:21.038Z"
    }
   },
   "outputs": [],
   "source": [
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.203590Z",
     "start_time": "2019-08-20T22:46:21.045Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_x\n",
    "y = df_y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.85, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Lasso Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.205585Z",
     "start_time": "2019-08-20T22:46:21.345Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('lr', Lasso())\n",
    "])\n",
    "pipe_params = {\n",
    "    'lr__alpha': [0, .5, 1, 1.5, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.207581Z",
     "start_time": "2019-08-20T22:46:21.354Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "print('CV Score:', gs.best_score_)\n",
    "print('train', rmse(gs.predict(X_train), y_train))\n",
    "print('test', rmse(gs.predict(X_test), y_test))\n",
    "print('Param:', gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Linear regression model with Lasso already proved better than Nicholas' best model suggesting that added LC and a interaction terms does offer more predictive power"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.209575Z",
     "start_time": "2019-08-20T22:46:21.969Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('rf', RandomForestRegressor())\n",
    "])\n",
    "pipe_params = {\n",
    "    'rf__n_estimators': [20, 25, 30],\n",
    "    'rf__max_depth': [50, 60, 70, 80],\n",
    "    'rf__max_features': ['auto'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.211573Z",
     "start_time": "2019-08-20T22:46:22.125Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "pred_train = gs.predict(X_train)\n",
    "pred_test = gs.predict(X_test)\n",
    "y_hat = np.ceil(pred_test)\n",
    "y_hat = np.where(y_hat==7, 6, y_hat)\n",
    "y_hat = np.where(y_hat==-0, 0, y_hat) \n",
    "print('CV Score:', gs.best_score_)\n",
    "print('RMSE Train:', rmse(pred_train, y_train))\n",
    "print('RMSE Test:', rmse(pred_test, y_test))\n",
    "print('Test Accuracy:', accuracy_score(y_hat, y_test))\n",
    "print('Param:', gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.213564Z",
     "start_time": "2019-08-20T22:46:22.132Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "diff = y_test - y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.216557Z",
     "start_time": "2019-08-20T22:46:22.137Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "diff.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.218551Z",
     "start_time": "2019-08-20T22:46:22.143Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "diff[np.abs(diff) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:39:35.748106Z",
     "start_time": "2019-08-20T22:39:35.742125Z"
    },
    "hidden": true
   },
   "source": [
    "Fairly effective, but tuning doesn't seem to increase effictiveness as much"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.220553Z",
     "start_time": "2019-08-20T22:46:22.808Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('gb', GradientBoostingRegressor())\n",
    "])\n",
    "pipe_params = {\n",
    "    'gb__n_estimators': [80, 90, 100, 110],\n",
    "    'gb__learning_rate': [0.1, 0.2, 0.3],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.222539Z",
     "start_time": "2019-08-20T22:46:22.815Z"
    }
   },
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs.fit(X_train, y_train)\n",
    "pred_train = gs.predict(X_train)\n",
    "pred_test = gs.predict(X_test)\n",
    "y_hat = np.ceil(pred_test)\n",
    "y_hat = np.where(y_hat==7, 6, y_hat)\n",
    "y_hat = np.where(y_hat==8, 6, y_hat)\n",
    "y_hat = np.where(y_hat==-0, 0, y_hat) \n",
    "print('CV Score:', gs.best_score_)\n",
    "print('RMSE Train:', rmse(pred_train, y_train))\n",
    "print('RMSE Test:', rmse(pred_test, y_test))\n",
    "print('Test Accuracy:', accuracy_score(y_hat, y_test))\n",
    "print('Param:', gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.224534Z",
     "start_time": "2019-08-20T22:46:22.823Z"
    }
   },
   "outputs": [],
   "source": [
    "diff = y_test - y_hat\n",
    "diff.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.226529Z",
     "start_time": "2019-08-20T22:46:22.829Z"
    }
   },
   "outputs": [],
   "source": [
    "diff[np.abs(diff) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far the most effective with accuracy consistently over 60% and RMSE under 1. Going as high as 65% and as low as .96 with tuning. Seens to under predict in general so this can be fixed by maybe adding in coverage set up and type itneractions.  \n",
    "Best Cross Val Score is .74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.228524Z",
     "start_time": "2019-08-20T22:46:23.607Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df_x\n",
    "y = df_y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, train_size=.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.230518Z",
     "start_time": "2019-08-20T22:46:23.613Z"
    }
   },
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.233516Z",
     "start_time": "2019-08-20T22:46:23.619Z"
    }
   },
   "outputs": [],
   "source": [
    "nn = Sequential()\n",
    "nn.add(Dense(512, input_dim=X_train.shape[1], activation='relu'))\n",
    "nn.add(Dropout(0.5))\n",
    "nn.add(Dense(256,  activation='relu'))\n",
    "nn.add(Dropout(0.5))\n",
    "nn.add(Dense(1,  activation=None))\n",
    "nn.compile(loss=root_mean_squared_error, optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.235505Z",
     "start_time": "2019-08-20T22:46:23.625Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = nn.fit(X_train, y_train, epochs=100, batch_size=8, validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-20T22:46:46.237500Z",
     "start_time": "2019-08-20T22:46:23.632Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(hist.history['loss'], label='Training loss', color='violet')\n",
    "plt.plot(hist.history['val_loss'], label='Testing loss', color='lavender')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can't seem to get loss below that of Gradient Descent and Random Forest"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.273px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "675px",
    "left": "1047.09px",
    "right": "20px",
    "top": "-45px",
    "width": "302.545px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
